摘要：
无透镜全息显微成像技术因其带来了简单的系统结构、大视场和多维成像等便利而在显微成像领域扮演者一个重要的角色。我们从CMOS/CCD传感器中采集到干涉产生的强度图像中重构光场中包含了振幅和相位的波前信息，进而可以对样本进行振幅或相位成像，这其中涉及到相位恢复问题。近些年来，随着深度学习在计算成像问题上取得的一些成功，随之而来出现了一些使用深度学习方法进行相位恢复的工作。但是，这些方法往往要面对如泛化性，可解释性，重构效果等挑战。本文中，我们提出了一种深度神经网络架构，该网络受物理模型的启发，在逆问题中使用深度卷积网络代替非线性映射，并从不同离焦距离下采集的多帧全息图中获取信息和作为约束，以提高重构质量，尽管网络是以数据为驱动的，我们在损失函数部分利用正向传播模型达到自监督的策略，因此不需要获取大量消耗成本的真实标签。最后，通过对比实验，我们验证了所提出网络结构较现有的传统算法和深度学习方法具有更好的性能，通过销蚀实验，我们验证了网络中各个模块的有效性，和良好的复用性能。

引言：
无透镜全息显微成像技术是将样品与CCD/CMOS等传感器贴近，无需透镜、直接对样品进行成像的技术，较传统光学显微镜有结构简单、操作简便、视场大等优点，已被应用于微小组织结构检查、细胞形态数量分析、微生物检测等领域。全息技术的应用解决了光电传感器只能测量空间光场波前强度信息的问题，而通过解决成像逆问题，我们通过采集的全息图还可以得到波前的相位信息，这可以解决在明场显微镜中存在的，对于不染色的活体生物体成像不显眼的问题，无法感知样本深度信息等问题。

在经典的相位恢复方法中，最常用的是基于G-S算法及在其基础上加以改进的迭代算法，这些算法不能仅从单帧全息图中恢复相位信息，而需要获取额外的信息支持，例如已知样本平面的先验知识，或者在改变系统参数（离焦距离，光波长，光源角度等）后获取多帧全息图加入迭代过程。近年来，深度学习方法在图像逆问题上得到了广泛的应用，一些基于深度神经网络的相位恢复方法被提出，首先被提出的是一些端到端的网络如图1a，这些网络由数据驱动，需要在大量的数据集上进行训练，尽管这些方法带来了不错的视觉效果，但是这些方法普遍面临着一些问题，包括重构结果细节的真实性、网络的低可解释性、弱泛化性能和获取数据集真实的相位信息作为ground truth而带来的大量工作等。最近，一些非数据驱动的神经网络结构被提出如图1b，这些网络应用了被称为“untrained”的概念，在重构过程中，将采集到的全息图送入网络，网络的输出作为所预测的波前信息，这个输出随后通过已知的前向成像过程，然后将输出结果与采集到的全息图计算损失函数，通过网络框架提供的优化器，进行梯度下降，当误差降到一定的范围时，将网络输出的波前信息作为所求复振幅的预测。事实上，这种“untrained”网络同样可以视为迭代算法。与传统方法不同，这些已经出现的端到端或非端到端的深度学习方法，往往倾向于使用单帧全息图进行相位恢复，因为这有利于网络的构建，另外使用单帧全息图的确会带来硬件系统结构上的便利性，但问题随之而来，由于缺乏额外信息的支持，在同传统多帧算法的比较中，网络的重构效果往往不尽如人意如图2。尽管这种单帧对多帧的比较听起来并不公平，但事实上，构造适用于多帧采集的神经网络是可行的，并且随之而来的是更好的重构效果。

前向模型：
菲涅尔衍射模型：


